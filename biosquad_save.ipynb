{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ccbd7b-7551-4806-87d9-a57cf3183e3f",
   "metadata": {},
   "source": [
    "# **BIOSQUAD Final Project Notebook**\n",
    "## UN5550 Fall 2025\n",
    "<p> Lily Karg, Carly Steckling, Peter Briggs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728325cf-818e-440d-b428-e99a815ec41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Set Up\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb0755-83a1-4e8c-91a9-c94204b672f9",
   "metadata": {},
   "source": [
    "# **Load LCCLUC Datafiles from GitHub Repository**\n",
    "<p> We have downloaded LCCLUC data from the Multi-Resolution Land Characteristics Consortium and saved them in our remote GitHub repository.</p>\n",
    "<p> Repository link:\n",
    "<a href=https://github.com/lilykarg/biosquad/tree/main](https://github.com/lilykarg/biosquad/tree/main>https://github.com/lilykarg/biosquad/tree/main](https://github.com/lilykarg/biosquad/tree/main</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c91d5a-9d2f-4ee8-9b2b-f5f5290f9084",
   "metadata": {},
   "source": [
    "## GitHub Access Token\n",
    "\n",
    "The GitHub repository is private, so an access token is needed to extract the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d14e5be-9583-492f-b05e-97a22446db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GitHub access token to pull data from our repository\n",
    "# token = \"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\"\n",
    "pete_token = \"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\"\n",
    "headers = {\"Authorization\": f\"token {pete_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403edf54-55de-4530-a7a8-5281809311a9",
   "metadata": {},
   "source": [
    "## Custom Function for importing LCC XML files\n",
    "We are using the xml.etree.ElementTree library to grab and process our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db19c1aa-116d-47e9-aa6a-9c64624fb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for importing all XML LCC data files from GitHub repositroy\n",
    "def parse_lcc_xml(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to download {url}: {response.status_code}\")\n",
    "        return None\n",
    "    root = ET.fromstring(response.content) \n",
    "\n",
    "    # extract the feature names\n",
    "    feature_names = [feature.find('Name').text for feature in root.findall('.//GDALRasterAttributeTable/FieldDefn')]\n",
    "\n",
    "    # extract the rows\n",
    "    rows = []\n",
    "    for row in root.findall('.//GDALRasterAttributeTable/Row'):\n",
    "        rows.append([f.text for f in row.findall('F')])\n",
    "\n",
    "    lcc_df = pd.DataFrame(rows, columns=feature_names)\n",
    "\n",
    "    # convert to values in each column to numeric values and pass if values are strings\n",
    "    for col in lcc_df.columns:\n",
    "        try:\n",
    "            lcc_df[col] = pd.to_numeric(lcc_df[col])\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return lcc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa20509-dae2-4c91-baf9-b08baf28e421",
   "metadata": {},
   "source": [
    "## Import and Pre-Process the LCC Data files\n",
    "\n",
    "This method uses a list of the file URLs to import the data, appending the data from each annual file into a master dataframe. The annual files do not contain information about the year from which the data was collected, so a column with the year is added by pulling the year from the file names.\n",
    "\n",
    "This code could be improved by finding a different way to import the data files without having to specify each file's URL from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c1c7ea-0682-40db-9147-a10ebd851bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2020.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2019.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2018.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2017.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2016.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2015.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2014.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2013.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2012.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2011.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2010.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2009.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2008.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2007.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2006.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2005.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2004.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2003.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2002.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2001.tif.aux.xml: 404\n",
      "Failed to download https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2000.tif.aux.xml: 404\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m         all_lcc_dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Concat all yearly LCC dataframes to a master dataframe\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m combined_lcc_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_lcc_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/.conda/envs/un5550fa25/lib/python3.10/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.conda/envs/un5550fa25/lib/python3.10/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/.conda/envs/un5550fa25/lib/python3.10/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Import and combine all XML LCC data files ----\n",
    "# this might pose a problem because it doesn't pull the year information with the files...!\n",
    "    \n",
    "# There \n",
    "# List raw data URLs:\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2020.tif.aux.xml\", #2020\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2019.tif.aux.xml\", #2019\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2018.tif.aux.xml\", #2018\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2017.tif.aux.xml\", #2017\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2016.tif.aux.xml\", #2016\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2015.tif.aux.xml\", #2015\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2014.tif.aux.xml\", #2014\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2013.tif.aux.xml\", #2013\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2012.tif.aux.xml\", #2012\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2011.tif.aux.xml\", #2011\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2010.tif.aux.xml\", #2010\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2009.tif.aux.xml\", #2009\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2008.tif.aux.xml\", #2008\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2007.tif.aux.xml\", #2007\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2006.tif.aux.xml\", #2006\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2005.tif.aux.xml\", #2005\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2004.tif.aux.xml\", #2004\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2003.tif.aux.xml\", #2003\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2002.tif.aux.xml\", #2002\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2001.tif.aux.xml\", #2001\n",
    "    \"https://raw.githubusercontent.com/lilykarg/biosquad/refs/heads/main/data/lccluc/2000.tif.aux.xml\" #2000\n",
    "]\n",
    "\n",
    "# Append to each yearly LCC file to its own dataframe and store in a list\n",
    "all_lcc_dfs = []\n",
    "for url in urls:\n",
    "    df = parse_lcc_xml(url)\n",
    "    if df is not None:\n",
    "        # Extract the filename from the URL\n",
    "        filename = os.path.basename(url)\n",
    "        \n",
    "        # Extract the year from the start of the filename \n",
    "        year = filename.split(\".\")[0]\n",
    "        \n",
    "        # Add 'year' column\n",
    "        df['year'] = int(year)\n",
    "        \n",
    "        all_lcc_dfs.append(df)\n",
    "\n",
    "# Concat all yearly LCC dataframes to a master dataframe\n",
    "combined_lcc_df = pd.concat(all_lcc_dfs, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de4fe5-5650-4ef9-8631-e17ec52c4bb7",
   "metadata": {},
   "source": [
    "#### Progress Update 1:\n",
    "The first step we made in our project methods was to import and combine all of the XML land cover change (LCC) files. We created a list of the raw data URLs into `urls`. Each URL was put into its own dataframe using a `for` loop to go through the list of URLs and then an `if` loop to extract the filename. A challenge in this step was that the extracted data did not include the year the data was taken in. To overcome this, we also extracted the year by splitting the filename in the `if` loop and put the year information in a new `‘year’` column in the dataframe with the corresponding filename within the list `all_lcc_dfs`. Then, we used a `concat` to put all of the LCC filenames and years in the same dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ce67d-5c65-4098-a132-f7f4c5162ea7",
   "metadata": {},
   "source": [
    "## Processing LCC Data\n",
    "### Land Type Conversions Groupings\n",
    "\n",
    "Each land cover change will be binned in groupings to reflect main land cover changes of interest. The groupings will be as follows:*\n",
    "\n",
    "Forest to agriculture: \n",
    "* \"Deciduous Forest to Cultivated Crops\", \n",
    "* \"Evergreen Forest to Cultivated Crops\", \n",
    "* \"Mixed Forest to Cultivated Crops\"\n",
    "\n",
    "Forest to developed: \n",
    "* \"Deciduous Forest to Developed, High Intensity\", \n",
    "* \"Deciduous Forest to Developed, Medium Intensity\",\n",
    "* \"Deciduous Forest to Developed, Low Intensity\",\n",
    "* \"Deciduous Forest to Developed, Open Space\",\n",
    "* repeat for other forest types\n",
    "\n",
    "Ice cover to open ocean: \n",
    "* \"Barren Land to Open Water\"\n",
    "* \"Perrenial Ice/Snow to Open Water\"\n",
    "\n",
    "Wetlands to impervious surfaces:\n",
    "* \"Woody Wetlands to Developed, High Intensity\"\n",
    "* \"Emergent Herbaceous Wetlands to Developed, High Intensity\"\n",
    "\n",
    "Vegetation to barren: \n",
    "* \"Woody Wetlands to Barren Land\"\n",
    "* \"Shrub/Scrub to Barren Land\"\n",
    "* \"Pasture/Hay to Barren Land\"\n",
    "* \"Mixed Forest to Barren Land\"\n",
    "* \"Grassland/Herbaceous to Barren Land\"\n",
    "* \"Evergreen Forest to Barren Land\"\n",
    "* \"Emergent Herbaceous Wetlands to Barren Land\"\n",
    "* \"Deciduous Forest to Barren Land\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebac43a-c485-4900-b7fd-8fd1282c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter LCC dataset to only include the major land conversion groupings:\n",
    "\n",
    "# Map the LCC \"classes\" to the main groups\n",
    "lcc_group_map = {\n",
    "    # Forest to Agriculture\n",
    "    \"Deciduous Forest to Cultivated Crops\": \"Forest to Agriculture\",\n",
    "    \"Evergreen Forest to Cultivated Crops\": \"Forest to Agriculture\",\n",
    "    \"Mixed Forest to Cultivated Crops\": \"Forest to Agriculture\",\n",
    "    \n",
    "    # Forest to Developed\n",
    "    \"Deciduous Forest to Developed, High Intensity\": \"Forest to Developed\",\n",
    "    \"Deciduous Forest to Developed, Medium Intensity\": \"Forest to Developed\",\n",
    "    \"Deciduous Forest to Developed, Low Intensity\": \"Forest to Developed\",\n",
    "    \"Deciduous Forest to Developed, Open Space\": \"Forest to Developed\",\n",
    "    \"Evergreen Forest to Developed, High Intensity\": \"Forest to Developed\",\n",
    "    \"Evergreen Forest to Developed, Medium Intensity\": \"Forest to Developed\",\n",
    "    \"Evergreen Forest to Developed, Low Intensity\": \"Forest to Developed\",\n",
    "    \"Evergreen Forest to Developed, Open Space\": \"Forest to Developed\",\n",
    "    \"Mixed Forest to Developed, High Intensity\": \"Forest to Developed\",\n",
    "    \"Mixed Forest to Developed, Medium Intensity\": \"Forest to Developed\",\n",
    "    \"Mixed Forest to Developed, Low Intensity\": \"Forest to Developed\",\n",
    "    \"Mixed Forest to Developed, Open Space\": \"Forest to Developed\",\n",
    "    \n",
    "    # Ice cover to Open Ocean\n",
    "    \"Barren Land to Open Water\": \"Ice cover to Open Ocean\",\n",
    "    \"Perennial Ice/Snow to Open Water\": \"Ice cover to Open Ocean\",\n",
    "    \n",
    "    # Wetlands to Impervious Surfaces\n",
    "    \"Woody Wetlands to Developed, High Intensity\": \"Wetlands to Impervious Surfaces\",\n",
    "    \"Emergent Herbaceous Wetlands to Developed, High Intensity\": \"Wetlands to Impervious Surfaces\",\n",
    "    \n",
    "    # Vegetation to Barren\n",
    "    \"Woody Wetlands to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Shrub/Scrub to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Pasture/Hay to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Mixed Forest to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Grassland/Herbaceous to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Evergreen Forest to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Emergent Herbaceous Wetlands to Barren Land\": \"Vegetation to Barren\",\n",
    "    \"Deciduous Forest to Barren Land\": \"Vegetation to Barren\",\n",
    "}\n",
    "\n",
    "# apply mapping to dataframe and create a new column called\n",
    "combined_lcc_df['LCC Main Group'] = combined_lcc_df['NLCD Land Cover Class'].map(lcc_group_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f63b07-592c-4503-8652-a061d27d5a6c",
   "metadata": {},
   "source": [
    "#### Progress Update 2:\n",
    "We faced another challenge while creating the figure to represent the number of pixel counts in each pre-determined group of LCC separated by year. We had been trying to use the `.count()` aggregation to count the number of pixels, but realized that by using `.count()`, we had actually been counting the number of LCC sub-groups in the `lcc_group_map`. For example, the sub-groups “Woody Wetlands to Developed, High Intensity” and “Emergent Herbaceous Wetlands to Developed, High Intensity” would output a count of 2 for the “Wetlands to Impervious Surfaces” LCC group. To fix this problem, we used the column `'Pixel Count'` instead of the aggregation while creating the figure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041d28e-0d02-40e0-876e-f70b38494a43",
   "metadata": {},
   "source": [
    "### Converting Pixels to Area (square kilometer)\n",
    "\n",
    "Land cover changes are visualized in pixels on an image file, or *.tif*. Here, we can visualize spatial data by converting pixel counts for each main LCC group into an area. We are in the process of writing a mapping code for to take each $900m^2$ pixel and turn it into $km^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb31ba-a88d-4e30-80a5-d7128fe21bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pixels to m^2 and then km^2\n",
    "\n",
    "## code in progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f54e8d-7bda-4d53-9f35-206078dff20d",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### Plotting Main LCC Groups Pixel Counts per Year\n",
    "\n",
    "Before converting pixel counts to areas, we're exploring the spatial extent of land cover change through pixel counts, or how much of the map is dominated by a certain LCC type. Here, we've plotted the year (x-axis) against the raw pixel counts (y-axis), where color represents the main LCC groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d623567-73cf-4b79-9199-523bff177f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pixel count data for each LCC group by year\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data=combined_lcc_df, x='year', y='Pixel Count', hue='LCC Main Group')\n",
    "\n",
    "plt.title(\"Main LCC Group Pixel Counts by Year\")\n",
    "plt.ylabel(\"Pixel Count\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.legend(title=\"LCC Group\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a6da7-e333-4295-8a64-9bc291cb39df",
   "metadata": {},
   "source": [
    "## **Load GPP Data from GitHub Repository**\n",
    "\n",
    "Another challenge we are currently working on is loading the GPP data. This is a challenge because the GPP data is at a much higher resolution than the LCC data in both temporal and spatial scales. Due to this, we are still in the process of extracting and importing the GPP data from the NASA Earth Observation dataset. \n",
    "\n",
    "We will likely use a similar approach as the XML data import method, using a `for` loop to pull the data off of GitHub by URL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11160be-034b-4949-aa84-22565cb4d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pete_token, type(pete_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95e5d9-4d16-47e0-8c97-f35e82f3b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2 = pd.read_csv(\"https://raw.githubusercontent.com/lilykarg/biosquad/main/data/gpp/co2_gr_gl.csv\")\n",
    "\n",
    "CO2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-un5550fa25] *",
   "language": "python",
   "name": "conda-env-.conda-un5550fa25-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
